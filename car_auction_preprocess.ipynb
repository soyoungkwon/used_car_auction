{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('FCG Germany GmbH_Data Scientist_case study_Inspections.csv')\n",
    "df_auctions = pd.read_csv('FCG Germany GmbH_Data Scientist_case study_Auctions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json object to pandas \n",
    "\n",
    "'inspection_report', 'category_score'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add: inspection_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generrate_inspection(row, column_name, the_key):\n",
    "    json_data = row[column_name]#['inspection_report']\n",
    "    try:\n",
    "        python_obj = json.loads(json_data)\n",
    "        if the_key in python_obj.keys():\n",
    "            return python_obj[the_key]\n",
    "        else:\n",
    "            return float(\"nan\")\n",
    "    except:\n",
    "        return float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This take long to run:\n",
    "## Run to add features about inspection_report\n",
    "column_name = 'inspection_report'\n",
    "df_extend = df.copy()\n",
    "insp_json_data = df.iloc[0][column_name]#.inspection_report\n",
    "for thekey in list(json.loads(insp_json_data).keys()):\n",
    "    col_name = 'insp_rep_' + thekey\n",
    "    df_extend[col_name] = df_extend.apply( generrate_inspection, args=[column_name, thekey], axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add: category_scores as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generrate_cat_data(row, column_name, the_key):\n",
    "    json_data = row[column_name]\n",
    "    try:\n",
    "        tmp_df = pd.DataFrame(json.loads(json_data)).set_index('id')\n",
    "        if the_key in list(tmp_df.index):\n",
    "            return tmp_df.loc[the_key]['score']\n",
    "        else:\n",
    "            return float(\"nan\")\n",
    "    except:\n",
    "        return float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This take long to run:\n",
    "## Run to add features about category_scores\n",
    "column_name2 = 'category_scores'\n",
    "df_extend_test = df_extend.copy()\n",
    "cate_json_data = df.iloc[0][column_name2]\n",
    "for doc in list(json.loads(cate_json_data)) :\n",
    "    col_name = 'cat_score_' + doc['id']\n",
    "    df_extend_test[col_name] = df_extend_test.apply( generrate_cat_data, args=[column_name2, doc['id']], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21160, 215), (21160, 219))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extend_test.shape, df_extend_load.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop: with a lot null values, consider drop these column\n",
    "col_alot_null = ['deleted_at', 'end_time', 'insp_rep_NIK', 'insp_rep_paintscannerFrontBumper']\n",
    "df_extend_load = df_extend_load.drop(col_alot_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21160, 215)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extend_test = df_extend_load.copy()\n",
    "df_extend_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to fillna -1: car_id, insp_rep_priceInspectorExpectation\n",
    "\n",
    "df_extend_test['car_id'] = df_extend_test['car_id'].fillna(-1)\n",
    "df_extend_test['insp_rep_priceInspectorExpectation'] = df_extend_test['insp_rep_priceInspectorExpectation'].fillna(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21160, 215)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extend_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF to Boolean values\n",
    "Convert True False to 1 0<br>\n",
    "how to deal with NAN ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bool_keys = []\n",
    "for key, val in json.loads(df.iloc[0].inspection_report).items():\n",
    "    if type(val) == type(True):\n",
    "        #print (key, val, type(val))\n",
    "        list_bool_keys += ['insp_rep_'+key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_bool_keys)\n",
    "for iname in df_extend_test.columns:\n",
    "    if iname in list_bool_keys: \n",
    "        df_extend_test[iname] = df_extend_test[iname].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime column\n",
    "- Convert datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datetime\n",
    "# inspection_date, insp_rep_tax\n",
    "df_extend_test['inspection_date']= pd.to_datetime(df_extend_test['inspection_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_my_to_datetime(row):\n",
    "    try:\n",
    "        out = datetime.strptime(row['insp_rep_tax'], '%m/%Y')\n",
    "        return out\n",
    "    except: \n",
    "        return datetime(5000,12,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extend_test['insp_rep_tax'] = df_extend_test.apply( str_my_to_datetime , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further checking column type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on, off, n/a\n",
    "list_dummie_onoffna = [\n",
    "    'insp_rep_blower',\n",
    "    'insp_rep_armRest',\n",
    "    'insp_rep_heating',\n",
    "    'insp_rep_headRest',\n",
    "    'insp_rep_fogLightLeft',\n",
    "    'insp_rep_discBreakLeft',\n",
    "    'insp_rep_fogLightRight',\n",
    "    'insp_rep_discBreakRight',\n",
    "    'insp_rep_dashControlDeFog',\n",
    "    'insp_rep_matchingVinNumber',\n",
    "    'insp_rep_trunkDoorFunction',\n",
    "    'insp_rep_extraMonitorFunction',\n",
    "    'insp_rep_matchingEngineNumber',\n",
    "    'insp_rep_sideMirrorLeftAutoRetracts',\n",
    "    'insp_rep_sideMirrorRightAutoRetracts'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_na_with_notavail(row, col_name):\n",
    "    try:\n",
    "        if row[col_name] == 'n/a':\n",
    "            return 'notavail'\n",
    "        else:\n",
    "            return row[col_name]\n",
    "    except: \n",
    "        return 'notavail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for onoffvar in list_dummie_onoffna:\n",
    "    df_extend_test[onoffvar] = df_extend_test.apply( replace_na_with_notavail , args = [onoffvar], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Vars\n",
    "to onehotencoding, drop useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding lists\n",
    "list_dummie = []\n",
    "\n",
    "# categorical\n",
    "list_dummie += [\n",
    "    'inspection_leadsource',\n",
    "    'insp_rep_bpkb',\n",
    "    'insp_rep_make',\n",
    "    'insp_rep_model',\n",
    "    'insp_rep_ownership'\n",
    "]\n",
    "\n",
    "# on, off, n/a\n",
    "list_dummie += list_dummie_onoffna\n",
    "\n",
    "# other categorical\n",
    "list_dummie += [\n",
    "    'insp_rep_fuel',\n",
    "    'insp_rep_leadsource',\n",
    "    'insp_rep_formAOption',\n",
    "    'insp_rep_chassisColor',\n",
    "    'insp_rep_transmission',\n",
    "    'insp_rep_frontAirbagOption',\n",
    "    'insp_rep_1stOwnershipOption'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will drop : insp_rep_trim : e.g. '1.5 RS Bensin' >> seems not useful\n",
    "df_extend_test = df_extend_test.drop('insp_rep_trim', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot coding the other categorical vars\n",
    "dfDummies = pd.get_dummies(df_extend_test[list_dummie])\n",
    "df_extend_test = pd.concat([df_extend_test, dfDummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join table with price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_auctions = pd.merge(df_auctions, df_model, on='car_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column : how old is the car?\n",
    "auction_start_date - manufactured_year<br>\n",
    "year_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-08-03 12:20:00')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_auctions['auction_start_date']= pd.to_datetime(df_model_auctions['auction_start_date']) \n",
    "df_model_auctions['auction_start_date'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timediff_year (row, varpast, varnow):\n",
    "    try:\n",
    "        ans_years = row[varnow].year - row[varpast]\n",
    "        return ans_years\n",
    "    except: \n",
    "        return float('nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_auctions['year_to_date'] = df_model_auctions.apply( \n",
    "        make_timediff_year , args = ['insp_rep_year','auction_start_date'], axis = 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused column\n",
    "# from inspection table\n",
    "unused_cols = []\n",
    "unused_cols += [\n",
    "    'inspection_id',\n",
    "    'car_id',\n",
    "    'inspection_date',\n",
    "    'category_scores',\n",
    "    'inspection_report',\n",
    "    'start_time',\n",
    "    'insp_rep_tax',\n",
    "    'insp_rep_year',\n",
    "    'insp_rep_lastService',\n",
    "    \n",
    "]\n",
    "unused_cols += list_dummie\n",
    "\n",
    "# from auction table\n",
    "unused_cols += [\n",
    "    'auction_id',\n",
    "    'auction_created_date',\n",
    "    'auction_start_date',\n",
    "    'auction_original_end_date',\n",
    "    'auction_end_date',\n",
    "    'buy_now_enabled',\n",
    "    'winning_bid_price',\n",
    "    'auction_buy_now_price',\n",
    "    'won_with_buy_now',\n",
    "    'winner_dealer_id',\n",
    "    'has_winner',\n",
    "    'number_of_bids',\n",
    "    'number_of_bidders'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_auctions = df_model_auctions.drop(unused_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns should be 0 if it's empty ''\n",
    "str_s = [\n",
    "    'returned', #bool\n",
    "    'insp_rep_keySets',\n",
    "    'insp_rep_cylinderCapacity',\n",
    "    'insp_rep_priceSellerExpectation',\n",
    "    'insp_rep_priceInspectorExpectation',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for str_ in str_s: \n",
    "    df_model_auctions[str_] = df_model_auctions[str_].apply(lambda x: 0 if x =='' else x)\n",
    "    df_model_auctions[str_] = df_model_auctions[str_].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_auctions = df_model_auctions[(df_model_auctions['insp_rep_priceSellerExpectation'] > 0) & \n",
    "                 (df_model_auctions['insp_rep_priceInspectorExpectation'] > 0)]\n",
    "df_model_auctions = df_model_auctions.reset_index(drop = True)\n",
    "# I think these price should be imposrtant so drop those 49 obs that has no info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_auctions = df_model_auctions.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_auctions.to_csv('used_car_extend_model_clean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
